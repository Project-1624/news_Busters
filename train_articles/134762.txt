The Identity of Indiscernibles (Stanford Encyclopedia of Philosophy)
First published Wed Jul 31, 1996; substantive revision Sun Aug 15, 2010

The Identity of Indiscernibles is a principle of analytic ontology first explicitly formulated by Wilhelm Gottfried Leibniz in his Discourse on Metaphysics, Section 9 (Loemker 1969: 308). It states that no two distinct things exactly resemble each other. This is often referred to as ‘Leibniz's Law’ and is typically understood to mean that no two objects have exactly the same properties. The Identity of Indiscernibles is of interest because it raises questions about the factors which individuate qualitatively identical objects. Recent work on the interpretation of quantum mechanics suggests that the principle fails in the quantum domain (see French 2006).

The Identity of Indiscernibles (hereafter called the Principle) is usually formulated as follows: if, for every property F, object x has F if and only if object y has F, then x is identical to y. Or in the notation of symbolic logic:

∀F(Fx ↔ Fy) → x=y.

This formulation of the Principle is equivalent to the Dissimilarity of the Diverse as McTaggart called it, namely: if x and y are distinct then there is at least one property that x has and y does not, or vice versa.

The converse of the Principle, x=y → ∀F(Fx ↔ Fy), is called the Indiscernibility of Identicals. Sometimes the conjunction of both principles, rather than the Principle by itself, is known as Leibniz's Law.

Thus formulated, the actual truth of the Principle seems unproblematic for medium-sized objects, such as rocks and trees, for they are complex enough to have distinguishing or individuating features, and hence may always be distinguished by some slight physical difference. But fundamental principles are widely held to be non-contingent. We might require, therefore, that the Principle should hold even for hypothetical cases of qualitatively identical medium sized objects (e.g., clones which, contrary to fact, really are molecule for molecule replicas). In that case, we shall need to distinguish such objects by their spatial relations to other objects (e.g., where they are on the surface of the planet). In that case the Principle is consistent with a universe in which there are three qualitatively identical spheres A, B, and C where B and C are 3 units apart, C and A are 4 units apart and A and B are 5 units apart. In such a universe, A's being 5 units from B distinguishes it from C, and A's being 4 units from C distinguishes it from B. The Principle often gets called into question, however, when we consider qualitatively identical objects in a symmetrical universe. Consider, for instance, a perfectly symmetrical universe consisting solely of three qualitatively identical spheres, A, B and C, each of which is the same distance, 2 units, away from the others. In this case there seems to be no property which distinguishes any of the spheres from any of the others. Some would defend the Principle even in this case by claiming that there are properties such as being that very object A. Call such a property a thisness or haecceity.

The possibility of resorting to thisnesses might make us query whether the usual formulation of the Principle is correct. For as initially stated the Principle told us that no two substances exactly resemble each other. Yet if A and B otherwise exactly resemble each other then, on a common intuition, the fact that A has the property being identical to A while B has the distinct property being identical to B cannot result in a respect in which A and B fail to resemble each other.

Rather than argue about these intuitions and hence argue as to which is the correct formulation of the Principle we may distinguish different formulations, and then discuss which, if any, of these are correct. To that end a distinction is commonly made between intrinsic and extrinsic properties. Here it might initially seem that extrinsic properties are those analysed in terms of some relation. But this is not correct. For the property being composed of two concentric spheres is intrinsic. For present purposes it suffices to have an intuitive grasp of the intrinsic/extrinsic distinction. (Or see Weatherson, 2008, §2.1.)

Another useful distinction is between the pure and the impure. A property is said to be impure if it is analysed in terms of a relation with some particular substance (e.g., being within a light year of the Sun). Otherwise it is pure (e.g., being within a light year of a star). Those two examples are both of extrinsic properties, but some intrinsic properties are impure, (e.g., being composed of the Earth and the Moon). According to my definitions all non-relational properties are pure.

Armed with these distinction we may ask which properties are to be considered when we formulate the Principle. Of the various possibilities two seem to be of greatest interest. The Strong version of the Principle restricts it to pure intrinsic properties, the Weak to pure properties. If we allow impure properties the Principle will be even weaker and, I would say, trivialised. For instance in the three sphere example the impure properties being 2 units from B and being 2 units from C are possessed by A and only A, yet intuitively they do not prevent exact resemblance between A, B and C. (For a different classification of principles, see Swinburne (1995.))

Suppose we take identity to be a relation and analyse thisnesses as relational properties, (So A's thisness is analysed as being identical to A). Then thisnesses will be impure but intrinsic. In that case the world consisting of the three qualitatively identical spheres 3, 4 and 5 units distance apart satisfies the Weak but not the Strong Principle. And the world with the three spheres each 2 units distance from the others satisfies neither version.

A further distinction is whether the Principle concerns all items in the ontology or it is restricted to just the category of substances (ie things which have properties and/or relations but are not themselves properties and/or relations.) It is usually thus restricted although Swinburne (1995) does consider, and defend, its application to such abstract objects as integers, times and places, without explicitly treating these as substance.

Most formulations of the Principle carry a prima facie commitment to an ontology of properties, but nominalists of various kinds should have little difficulty in providing suitable paraphrases to avoid this commitment. (For instance, by using plural quantification. See Boolos 1984, Linnebo 2009, §2.1.) Most interesting in this context is the way the Principle can be stated in terms of resemblance without any mention of properties at all. Thus the Strong Principle might be formulated as denying that distinct substances ever exactly resemble, and the Weak Principle as denying that distinct states of affairs ever exactly resemble.

Russell (e.g., 1940, Chapter 6) held that a substance just is a bundle of universals themselves related by a special relation between properties, known as compresence. If the universals in question are taken to be intrinsic properties, then Russell's theory implies the Strong Principle. (At least it seems to imply it, but see O'Leary-Hawthorne 1995, Zimmerman 1997 and Rodriguez 2004.) And if the status of substances is non-contingent then it implies the necessity of the Strong Principle. This is important because the most vulnerable version is clearly the Strong when it is held to be non-contingent. (See also Armstrong 1989, Chapter 4.)

(i) The Principle appeals to empiricists. For how could we ever have empirical evidence for two indiscernible items? If we did, empiricists might say, then they would have to be differently related to us. Unless we ourselves have exact replicas, which is implausible, we are the unique beings with pure properties X, Y, Z etc. Hence the empirically distinguishable objects have different pure properties, namely, being related in different ways to the unique things with X, Y, Z, etc. From this and the empiricist premiss that there are no things which are not empirically distinguishable, we would conclude that the Weak Principle holds. Presumably the premiss would not be proposed as anything more than contingently true. For there are possible situations in which there would be theoretical reasons for believing in indiscernible items as a consequence of a theory which best explains the empirical data. Thus we might come to hold a theory of the origins of the physical universe which had large amounts of empirical support, and which implied that, in addition to our enormously complicated universe, various simpler ones had been generated. For some of the simplest universes this theory might imply that there were exact replicas. In that case the Weak Principle would fail.

(ii) If we ignore quantum mechanics, we might well conclude that not merely the Weak Principle is contingently correct but even the Strong Principle. For unless we take space to be discrete, the classical mechanical situation would seem to be summed up by the Poincaré recurrence theorem which tells us that typically we get arbitrarily close to an exact repetition, but never get to one. (See Earman 1986, p. 130.)

(iii) Concerning the Weak Principle there has been an interesting development of a line of argument due to Black (1952) and Ayer (1954) in which it is proposed that there could be exact symmetry in the universe. In Black's example it is suggested that there could be a universe containing nothing but two exactly resembling spheres. In such a completely symmetrical universe the two spheres would be indiscernible. Against this has been noted, e.g., Hacking (1975), that such a completely symmetrical situation of two spheres could be re-interpreted as one sphere in a non-Euclidean space. So what might be described as a journey from one sphere to a qualitatively identical one 2 units apart could be redescribed as a journey around space back to the very same sphere. Quite generally it might be said that we may always redescribe apparent counter-examples to the Weak Principle so that qualitatively identical objects symmetrically situated are interpreted as the very same object. This Identity Defence, as Hawley (2009) calls it, is vulnerable to a version Adam's continuity argument. (1979)

A rejoinder to this is the continuity argument, essentially due to Adams (1979). It is granted that almost perfect symmetry is possible. For there could be a space with nothing in it but a sequence of spheres arranged in a line at equal distance without any intrinsic difference except that one of them is scratched. The identity defence is then committed to the counter-intuitive counterfactual “If there had been no scratch on a sphere the shape of space would have been different”.

In addition to this rejoinder, it should be noted that in only slightly more complicated examples the identification strategy is rather less persuasive than in the two sphere case. Consider the example of three qualitatively identical spheres arranged in a line, with the two outside ones the same distance from the middle one. The identification strategy would first require the two outer ones to be identified. But in that case there remain two qualitatively identical spheres, so these must in turn be identified. The upshot is that it is not merely the two spheres we took to be indistinguishable that are said to be identical but all three, including the middle one which seemed clearly distinguished from the other two by means of a pure relational property.

Adams may be interpreted as providing two arguments, the first being the continuity argument used above. The second is a modal argument relying on the Necessity of Identity and a suitably strong modal logic. Suppose there are two objects that are distinguished by accidental features, as it might be one of the spheres, A has a scratch, while the other B does not. Then it is possible that A has no scratch and hence possible that the spheres be indiscernible. If the Principle holds of necessity then that entails that it is possible that A = B. But by the Necessity of Identity that in turn entails that it is possibly necessary that A = B, so in S5 modal logic (or the weaker system B), it follows that A = B, which is absurd given that one has a scratch and the other does not. In this argument any accidental difference would suffice in place of the scratch.

Ignoring quantum mechanics we have, then, arguments that many find persuasive to show that both the Weak and the Strong Principle are contingently true but neither are necessarily so. For the relevance of quantum mechanics, see French 2006.

3.1 Recent Developments

O'Leary Hawthorne (1995) redescribes Black's example as a single sphere with two locations. If we accept either of Adams' argument it follows that discernible spheres can be redescribed as a single sphere with two locations but with incompatible properties in the locations, which is seriously counter-intuitive if not absurd (Hawley 2009 — see also her further criticisms.)

Another ingenious idea, suggested by Hawley, is that the two spheres be redescribed as a simple extended object, contrary to the intuition that a simple extended object must have a connected location (Markosian 1998). Once again, Adam's argument then implies that this redescription holds even of discernible objects of the same kind, threatening us with the somewhat counter-intuitive monist thesis that the universe is just one simple object. (For discussions of this latter thesis, see Potrc and Horgan 2008 and Schaffer 2008, §2.1.)

3.2 Identical Collocated Spheres?

Della Rocca invites us to consider the hypothesis that where we ordinarily think there is a single sphere in fact there are many identical collocated spheres, made up of precisely the same parts. (If they were not made up of the same parts then the mass of the twenty spheres would be twenty times that of one sphere, resulting in an empirical difference between the twenty sphere hypothesis and the one sphere hypothesis.) Intuitively this is absurd, and it is contrary to the Principle, but he challenges those who reject the Principle to explain why they reject the hypothesis. If they cannot, then this provides a case for the Principle. He considers the response that the Principle should be accepted only in the following qualified form:

There cannot be two or more indiscernible things with all the same parts in precisely the same place at the same time (2005, 488)

He argues that this concedes the need to explain non-identity, in which case the Principle itself is required in the case of simple things. Against Della Rocca, it may then be argued that for simples (things without parts) non-identity is a brute fact. This is in accord with the plausible weakening of the Principle of Sufficient Reason that restricts brute facts, even necessary ones, to the basic things that depend on nothing further.

3.3 The Third Grade Principle

Suppose we grant the possibility of otherwise indiscernible objects that are asymmetrically related. Then we have not just a counterexample to the weak Principle, but an interesting further weakening to the Third Grade Principle, namely that in cases where the Weak Principle fails the otherwise indiscernible objects stand in a symmetric but irreflexive relation — “Third Grade” because based on Quine's third grade of discrimination (1976). Recently Saunders has investigated this, noting that fermions but not bosons are third grade discriminable (2006).

Black's spheres are third grade discriminable because they stand in the symmetric relation of being at least two miles apart, but this example illustrates the objection that third grade discriminability presupposes non-identity (see French 2006). For suppose we identify the two spheres, treating space as cylindrical, then the geodesic joining the sphere would still be a geodesic and remain the same length. So we could quite naturally say the sphere was at least two miles from itself, unless we analyse that relation negatively as there being no path joining the spheres of less than two miles. But that negative relation only holds in the Black case because the spheres are not identified.

Leibniz prudently restricts the Principle to substances. Moreover, Leibniz is committed to saying that the extrinsic properties of substances supervene on the intrinsic ones, which collapses the distinction between the strong and the Weak Principles.

Although the details of Leibniz's metaphysics are debatable, the Principle would seem to follow from Leibniz's thesis of the priority of possibility. (See Leibniz's remarks on possible Adams in his 1686 letter to Arnauld, in Loemker 1969, p. 333.) It does not appear to require the Principle of Sufficient Reason, which Leibniz sometimes bases it on. (See for example Section 21 of Leibniz's fifth paper in his correspondence with Clarke (Loemker 1969, p. 699). See also Rodriguez-Pereyra 1999.) For Leibniz takes God to have created by actualising substances which already exist as possibilia. Hence there could only be indiscernible actual substances if there were indiscernible ones which were merely possible. Hence if the Principle holds for merely possible substances it holds for actual ones as well. There is, therefore, no point in speculating as to whether there might not be a sufficient reason to actualise two of a possible substance, for God cannot do that since both would have to be identical to the one possible substance. The Principle restricted to merely possible substances follows from Leibniz's identification of substances with complete concepts. For two complete concepts must differ in some conceptual respect and so be discernible.